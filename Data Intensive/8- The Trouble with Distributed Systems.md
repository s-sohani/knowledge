
تا اینجا ما در مورد فالت های زیادی حرف زدیم. باید بگم که تا اینجا خیلی خوشبین بودیم. واقعیت از انچه گفتیم دارک تر هست. ازین به بعت بیشتر بدبین خواهیم بود و فرض مون این خواهد بود که هر چیزی که ممکن است اشتباه پیش برود، قطعا اشتباه پیش خواهد رفت.

کار کردن با سیستم های توزیع شده قطعا سخت تر هست از نوشتن یه برنامه نرم افزاری برای یک سینگل کامپیوتر. دلیلش هم اینه که در سیستم های توزیع شده خیلی چیزا هستن که ممکنه منجر به خطا بشن. در انی فصل بیشتر درین مورد صحبت میکنیم.


## Faults and Partial Failures
در سیستم های توزیع شده ممکنه یه بخشی هایی از سیستم به صورت کاملا غیر قابل پیش بینی خراب بشه. در حالی که بخش های دیگری دارن درست کار میکنن. به ااین اتفاق میگن partial failure. دشواری قضیه اینجاست که کاملا nondeterministic هست. سیستم یه موقعی کار میکنه. یه موقعی fail میکنه. گاهی اصلا نمیشه فهمید آیا یه کار درست انجام شد یا fail شد.


## Cloud Computing and Supercomputing

طیفی از فلسفه ها در مورد چگونگی ساخت سیستم های محاسباتی در مقیاس بزرگ وجود دارد:
در یک سر طیف ابرکامپیوترها قرار دارن که هزاران پردازنده برای کارهای محاسباتی فشرده دارند.
در سر دیگر طیف cloud computing قرار داره که مربوط میشن به دیتاسنترهای 
در یک انتهای مقیاس، حوزه محاسبات با عملکرد بالا (HPC) قرار دارد. ابرکامپیوترها با هزاران CPU معمولاً برای کارهای محاسباتی علمی فشرده، مانند پیش‌بینی آب و هوا یا دینامیک مولکولی (شبیه‌سازی حرکت اتم‌ها و مولکول‌ها) استفاده می‌شوند.


در یک سوپرکامپیوتر، یه جاب معمولا هر از چندگاهی وضعیت محاسبات خودش رو به عنوان checkpoint  یه جا ذخیره میکنه. هرزمان یه نود دچار مشکل شد کل سیستم رو استاپ میکنه. بعد از تعمیر ان نود مشکل دارن، محاسبات رو از همان نقطه checkpoint ادامه میده. بنابراین سوپرکامیوتر ها بیشتر شبیه سینگل نود هستن تا توزیع شده. این سیستم ها یه partial failure رو مشابه یه total failure باهاش رفتار میکنن.

در این کتاب ما بیشتر روی سیستم هایی تمرکز داریم که سرویس های تحت وب میدن و معموا با سوپرکامیوتر ها متفاوتن.

سیستم های سرویس های آنلاین میدن براشون latency خیلی مهمه و نمیتونن برای یه partial failure کل سیستم رو متوقف کنن تا مشکل رو حل کنند. این سیستم ها با سیستم هایی که کارشون رو به صورت batch انجام میدن فرق دارن.

در سوپرکامیوترها سخت افزارهای مخصوصی به کار میره. هر نود تقریبا reliable هست. ارتباط نود ها بیشتر از طریق shared memory و remote direct memory access هست

اگر میخواهیم سیستم های توزیع شده بسازیم باید partial failure رو بپذیریم و تلاش کنیم سیستم  fault-tolerance طراحی کنیم.

حتی در سیستم های کوچیک که تعدا کمی نود دارند هم باید فکری برای partial failure کرده باشیم.

 هندل کردن فالت ها بادی بخضی از طراحی مون باشه در سیستم های توزیع شده.

اینجا داره میگه چطور ممکنه تو سیستمی که المان هاش قابل اعتماد نیستن، بتونیم توتالی سیستم رو reliable 

## Unreliable Networks


در این کتاب منظورمون از سیستم های توزیع شده سیستم های shared-nothing  هستن که از طریق نتوورک با هم ارتباط دارن.

ایمجا داره میگه چرا بیشتر از سیستم های Shared-nothing برای سیستم های توزیع شده استفاده میشه. چون ارزان تر هستن به خاطر اینکه سخت افزار خاض و پیچیده ای لازم ندارن.

در شبکه اینترنت که از نوع asynchronous packet network هست وقتی یه بسته ای ارسال میشه شبکه اصلا تضمین نمیده که اون بسته رو به مقصد برسونه. وقتی شما بسته ای رو ارسال میکنی و انتظار جواب داری:
۱- درخواستت ممکنه گم بشه
۲- درخواستت ممکنه تو یه صف شلوغی گیر کنه و دیر به مقصد برسه
۳- نود مقصد ممکنه از کار افتاده باشه
۴- نود مقصد ممکنه موقتا پاسخ دهی رو متوقف کرده باشه (مثلا یه پروسه طولانی برای  garbage collection ران کرده)
۵- نود مقصد درخواست شما رو گرفته و جواب هم داده ولی پاسخ شما در شبکه گم شده
۶- نود مقصد درخواست شما رو گرفته و پردازش هم کرده و جواب هم داده ولی پاسخ به دلایل مختلف مثلا شلوغی شبکه یا شلوغی خود شما دیر به دستتون میرسه



![[Pasted image 20250203150831.png]]




این مسائل در نتوورک های آسینک وجود دارن. وقتی درخواستی فرستادی و جوابی نگرفتی اصلا نمیتونی متوجه بشی دقیقا چرا جواب نگرفتی.

یه راه برای هندل کردن این بلاتکلیفی استفاده کردن از timeout هست. اگر مدت زمانی به اندازه timeout گذشت و جوابی نگرفتیم نتیجه میگیریم که قرار نیست جوابی بگیریم.

## Network Faults in Practice
شواهد و قراین نشون میده که هنوز هم همچنان نتوورک مستئد فالت هست، با وجود اینکه دهه ها هست که از پیدایش نتوورک میگذره.
در این پاراگراف داره چند نمونه مطالعه در این زمینه رو اشاره میکنه.

وقتی ارتباط یه بخشی از نتوورک از بخش دیگری قطع میشه میگن Network partitions اتفاق افتاده و یا netsplit. اما برای اینکه با پاژه پارتیشن در مبحث شاردینگ استباه نشه اینجا کلا به این مشکلات میگیم network fault.

 حتی اگر نرخ خرابی نتوورک کم هست باز هم اپلیکیشن شما باید بتونه این خرابی ها رو هندل کنه.
اگر اپلیکیشن مشا خرابی های شبکه ای رو هندل نکنه ممکنه اتفاقات بدی به دنبال خرابی شبکه رخ بده. مثلا یه کلاستر ممکنه به deadlocked برسه و  و دیگه نتونه به ریکوئست ها جواب بده حتی بعد از اینکه مشکل نتوورک حل بشه. یا ممکنه تمام دیتا و اطلاعات شما رو دیلیت کنه.

درضمن اپلیکیشن شما نه تنها باید بتونه خرابی های شبکه رو هندل بکنه بلکه باید بتونه به کاربر هم خطای مناسبی نشون بده

## Detecting Faults


خیلی از سیستم ها نیاز دارن که بتونن به صورت اتوماتیک نودهایی که دچار مشکل شده را شناسایی کنند. برای مثال:
یه لودبالانسر لازمه نود مرده یا شناسایی کنه تا لودی سمت آن نفرسته
در دیتابیس های توزیع شده تک لیدری،اگر لیدر از کار بیفته یکی از فالوورها باید متوجه و سریع  جای لیدر بشینه

متاسفانه انقدر در شبکه عدم قطعیت وجود داره که به این راحتی نمیشه متوجه شد نودی از کار افتاده یا نه. ولی در بعضی شرایط میشه یه سری فیدبک دریافت کرد که اینو نشون بدن:
- مثلا روی یه نود پراسس پاسخ دهنده crash کرده ولی سیستم عامل در حال اجراست. مثلا تو این شرایط بشه یه اسکریپتی داشت که به نودهای دیگه خبر بده که پراسس از کار افتاده
- یا مثلا فرض کنید شما دسترسی دارین به management interface نتوورک تون اینجوری مینین کوئری بزنین و از لینک های خراب مطلع بشین
- یا یه روتر اگر مطمسن بشه که نودی که شما دارین بهش درخواست میزنین در دسترس نیست خودش میتونه به شما پاسخ بده با یه ICMP Destination Unreachable packet.


اینکه از نودهای down شده سریع فیدبک بگیریم خیلی مفیده ولی نمیشه روش حساب کرد.


## Timeouts and Unbounded Delays

اگر timeout یه روش قابل قبول برای نشخیص فالت تو شبکه هست، سوال اینجاست که timeout چقدر باید باشه؟
اگر خیلی زیاد باشه فالت های نتوورک رو دیر متوجه میشیم. اگر خیلی کوتاه باشه خیلی از شرایط اوکی رو فالت تشخیص میدیم. مثلا یه نودی که حالش خوبه فقط یکم کند شده رو ما مرده تلقی خواهیم کرد.

وقتی یه نود نمرده ما بیاییم فکر کنیم که مرده مشکل ساز هست. اون نود داره کاری که بهش دادیم رو انجام میده، ما فکر مکنیم مرده و کار رو میفرستیم برای یه نود دیگه. همزمان دوجا داره کارمون انجام میشه.


وقتی تشخیص اینه که یه نود مرده، مسئولیتش باید به نود دیگری محول بشه. ایم محول کردن مسئولیت یه لود اضافه میندازه روی شبکه. حالا فک کن اون نود بیچاره واقعا نمرده بلکه فقط کند شده. این جابه جا کرد نمسئولیتش مشکل دیگری به نام cascading failure ایجاد میکنه

اگر در یک نتوورکی ماکزیمم تاخیر deliver شدن packet بین نودها برابر با dباشهو ماکزیمم زمان پردازش بسته توسط نودها r باشه میتونید بگیم تایم اوت مناسب برای این شبکه 2d+rهس ت. بیشتر از این زمان طول بکشه و جوابی نگیریم یعنی مشکلی پیش امده.


متاسفانه نتوورکی که ما باهاش کار میکنیم همچین تضمین هایی نمیده. شبکه های آسینک در واقع unbounded delays  دارن.

### Network congestion and queueing

تاخیر packet ها در شبکه بدلیل queue های موجود در بستر شبکه متغیر هست.
مثلا یهو نودهای بسیاری سعی میکنند با یه نود مشخص ارتباط بگیرن. حجم ترافیک به سمت اون نود زیاد میشه.بسته ها در صف های سوئیچ ها جمع میشن.  ازدحام در شبکه اتفاق میفته. Network congestion. اگر طول صف ها خیلی زیاد بشه ممکنه پسته ها از انتهای صف دراپ بشن.
مثلا بسته میرسه به مقصد ولی در مقصد تمام CPU مشغول هست. بسته تازه رسیده مجبور هست توسط سیستم عامل در صف منتظر بماند. بسته به لود موجد بسته منتظر یم ماند.
پروتکل TCP عمل flow control انجام میده و با مکانیزم congestion avoidance یا backpressure لود زیاد نندازه روی لینک های شبکه. این یعنی تو خود فرستنده هم صف وجود داره.


![[Pasted image 20250203151245.png]]

در پروتکل TCP اگر تا یه مدت زمان timeout ای acknowledged از نود مقصد دریافت نشه میذاره به حساب اینکه بسته گم شده و اونو مجدد ارسال میکنه. اپلیکیشن این packet loss و  retransmission رو احساس نمیکنه.


اپلیکیشن هایی که latency-sensitive هستن مثل videoconferencing یا Voice over IP میان از پروتکل UDP استفاده میکنن. امکان reliability کمتر هست در عوض تاخیر کمتره. 

در دیتاسنترهای کلود و multi-tenant همه منابع حتی شبکه و سويیچ ها بین ماشین های مختلف share هستن. وقتی یه workload بزرگی مثل MapReduce روی سیستم میفته خیلی احتمال اشباع شدن لینک ها نتوورک بالا میره. اگر کنترلی صورت نگیره ممکنه منابع توسط برخی ماشین ها بیش از سهم شون استفاده بشه. noisy neighbor.

یه راه برای کنترل استفاده از مکانیزم timeout هست.
حتی بهتر از اون میشه به جای استفاده از تایم اوت های ثابت مرتب متناسب با شرایط شبکه و ریسپانس تایم ها تایم اوت های متغیر استفاده کرد.

## Synchronous Versus Asynchronous Networks
شبکه تلفن fixed-line از نوع Synchronous هست. تو این شبکه queueing نداریم. برای یک ارتباط پهنای باند مشخص و اختصاصی در نظر گرفته میشه. در نتیجه این شبکه از نوع bounded delay هست.


### Can we not simply make network delays predictable?
آیا میشه تاخیر روی شبکه رو هم predictable کرد؟
شبکه تلفن با ارتباط TCP فرق داره. تو شبکه تلفن ما یه پهنای باند فیکس و رزرو شده داریم  برای هر ارتباط. در حالی که در شبکه TCP هر پکت به هر میزان پهنای باند که بتونه گیرش بیاد رو استفاده میکنه.
اگر شبکه اینترنت هم شبیه شبکه تلفن بود میشد روی تاخیر ها تضمین داد.
درواقع شبکه تلفن از نوع circuit-switched هست ولی اینترنت از نوع packet-switched هست.

شبکه اینترنت چون با هدف bursty traffic به وجود آماده، اینطور طراحی شده.
شبکه های circuit-switched برای انتقال صدا و ویدئو مناسب هستن که لازم دارن با یه تاخیر معقولی منتقل بشن. 
اما اگر داریم ایمیل میزنیم یا یه فایل ارسال میکنیم یا درخواست یک web page داریم  در این موارد ما نیاز نداریم یه پهنای باند ثابت و مشخصی در اختیار داشته باشیم.

وقتی ترافیک از نوع bursty هست مثل ارسال یه فایل، نمیدونی چه موقع به پهنای باند بالا نیاز داری، چه موقع نداری، اگر نیاز نداشته باشی داری یه پهنای باند زیادی رو رزرو میکنی درحالی که استفاده اش نمیکنی و اتلاف میشه. اما شبکه TCP کاملا با نرخ درخواست adapt میشه.

یه نتوورک هایی هم داریم که هیبریدی هستن یعنی هم circuit-switched هستن و هم packet-switched. مثل Asynchronous Transfer Mode (ATM)


اینجا میخواد بگه که Latency با Resource Utilization رابطه غیرمستقیمی داره. در نتوورک های circuit-switched منابع به تمام ارتباط ها تخصیص داده شده. چه ارتباطی بخواهد برقرار بشود و چه نشود. اینجا درسته میشه تاخیر رو گارانتی داد اما Resource Utilization کمتری داریم.
برعکس تو نتوورک packed-switched منابع کاملا داینامیک به درخواست ها اختصاص پیدا میکنه.  و متاسفانه درین شرایط خیلی نمیشه تاخیر رو تضمین کرد. 

## Unreliable Clocks
کلاک در چه مواردی نقش مهمی در اپلیکیشن ها داره؟
۱- وقتی اپلیکیشن میخواد تایم اوت رو روی یک درخواست متوجه بشه
۲- مثلا میخواد ریسپانس تایم یه سرویس رو اندازه بگیره.
۳- پارامتری مثل queries per second رو اندازه بگیره
۴- یه کاربر چه مدتی رو روی سایت سپری کرده
و کلی سناریوی دیگه


تو سیستم های توزیع شده time خیلی مساله حساسی هست.

هر ماشین کلاک خودشو داره که یه دیوایس سخت افزاری هست. ممکنه کلاک یه ماشین کندتر از کلاک ماشین دیگه باشه. روش هایی برای سینک کردن کلاک ماشین ها وجود داره. مثلا:
Network Time Protocol (NTP)
که سرورها میتونن باهم کلاک هاشون رو adjust کنن.

## Monotonic Versus Time-of-Day Clocks

دو مدل کلاک داریم:
Monotonic
Time-of-Day

### Time-of-day clocks

کلاک time-of-day که بهش wall-clock time هم میگن، تاریخ و زمان رو نشون میده. مثل:
clock_gettime(CLOCK_REALTIME) on Linux
System.currentTimeMillis() in Java that return number of seconds (or milliseconds) since the epoch: midnight UTC on January 1, 1970,

کلاک Time-of-day معمولا با NTP سینک میشه. که همین یه اذیت هایی داره.مثلا اگر ماشینی که میخاد timestamp اش رو سینک کنه از سرور NTP دور باشه اینجوری ممکنه به اجبار ساعتش رو ریست کرده و برگرده به نقطه قبلی. این پریدن ها به تایم قبلی باشه میشه اندازه گیری elapsed time در این ماشین ها خراب بشه.

این کلاک دقت کمتری هم داره. مثلا در سیستم های وندوز قدیمی step های زمانی 10ms هست.


### Monotonic clocks

کلاک Monotonic مناسب هست برای اندازه گرفتن duration، مثلا تشخیص تایم اوت شدن یا اندازه گیری ریسپانس-تایم. 
اینجا دیگه جامپ زمان به عقب نداریم.


مکانیزم کار کردن با کلاک monotonic اینطوریه که اول میخونیش. بعدا دوباره میخونیش و difference میگیری. معمولا این بار اول و بار دوم هردو روی یک ماشین انجام میشه. خیلی makes sense نمیکنه که بخواهیم بین تایم های ماشین های مختلف difference بگیریم.

اگر روی یه سرور چندتا CPU داشته باشیم ممکنه اونها تایم های متفاوتی داشته باشن. در این شرایط سیستم عامل میاد این اختلاف رو اصلاح میکنه و یه تایم یکسان رو به اپلیکیشن ها نشون میده. حتی اگر اون اپلیکیشن ها روی CPU های مختلف دارن اجرا میشن.

به روش NTP میشه فرکانس کلاک monotonic رو تنظیم کرد که به این کار میگن slewing کردن کلاک. به صورت پیش فرض اگر سرعت کلاک تند یا کند باشه میشه با NTP کم و زیادش کرد اما چیزی که در مورد کلاک های monotonic فرق داره اینه که NTP این کلاک ها رو عقب یا جلو نمیکنه. رزولوشن این کلاک ها معمولا خوبه(میکروثانیه). 

تو سیستم های توزیع شده استفاده کردن از کلاک های monotonic برای اندازه گیری elapsed time ایده خوبیه.

## Clock Synchronization and Accuracy

کلاک Monotonic نیازی به سینک شدن نداره. اما کلاک time-of-day لازم داره که با یه سرور NTP یا یه منبع بیرونی سینک بشه.
کلاک quartz در یک کامپیوتر خیلی دقیق نیست. ممکنه کلا متناسب با دمای ماشین تندتر یا کندتر تغییر بکنه.
اگر ساعت یک کامپیوتر خیلی با سرور NTP تفاوت داشته باشه ممکنه به جای سینک شدن کلاک خودش رو ریست کنه. اپلیکیشن هایی که قبل و بعد از این ریست ساعت رو میخونن ممکنه شاهد جامپ به جلو یا عقب باشن.

ارتباط با سرور NTP برای سینک کردن کلاک هم داره روی نتوورک انجام میشه و اگر نتوورک دچار congestion باشه این تاخیر در سینک شدن کلاینت ها با سرور اختلال ایجاد میکند.
ممکنه خود سرور NTP یه اشتباهاتی تو کانفیگش داشته باشه.

روی ماشین های مجازی که ساعت شون هم مجازی هست چالش های دیگری اضافه میشه. وقتی پردازنده بین ماشین ها share هست و ماشین ها cpu رو تحویل میدن و pause میشن این توقف باعث میشه بعدا جامپ به جلو نیاز داشته باشیم روی کلاک.

اصلا اگر اپلیکیشن شما روی دیوایسی کار میکنه که شما روش کنترلی ندارین، خیلی نمیتونین به کلاک اون دیوایس اعتماد کنید. ممکنه یکی از قصد روی دیوایس خودش تایم و ساعت اشتباه تنظیم کنه.



اگر بابت سینک کردن کلاک ها ریسورس قابل توجهی اختصاص بدیم این کار شدنی هست و میشه به دقت خوبی روی کلاک دست پیدا کرد.
مثلا به کمک گیرنده های GPS میشه به همچین دقتی رسید. از طریق پروتکل Precision Time Protocol (PTP)

## Relying on Synchronized Clocks

با اینکه در ظاهر استفاده از کلاک سادس ولی در عمل خیلی ممکنه ما رو بندازه تو دام.
همونطور که software باید فکر کنه که نتوورک کارش پر از مشکل هست و خودش باید فکری برای رفع مشکلات بکنه در مورد کلاک هم همینه. باید فرض کنه که کلاک ممکنه چقدر دقیق نباشه و خودش software فکر چاره باشه.

درنتیجه اگر software ای دارین که خیلی نیاز به کلاک سینک داره خودتون باید مرتب کلاک رو مانیتور کنید ببینید با ماشین های دیگه سینک هست یا نه. 


### Timestamps for ordering events

وقتی از timestamp و کلاک برای ترتیب event ها استفاده میکنیم مثلا زمانی که چندتا نود همزمان روی دیتابیس multi leader مینویسن میخواهیم بدونیم کدوم درخواست اول از همه اتفاق افتاده، این شرایط خیلی حساسن. شکل ۸-۳



![[Pasted image 20250203151727.png]]


تو این شکل کلاک ها با هم سینک نیستن. عمل x = 1  با تایم استمپ 42.004 منعکس میشه روی نود ۳ درحالی که روی نود ۳ عمل x+=1 با تایم استمپ 42.003 درج شده. 
اگر بر اساس called last write wins (LWW) بخواهیم  conflict  رو resolve کنیم (که خیلی در موراد مولتی لیدر رایج هست این متد) اثر عمل x+=1  میس خواهد شد

وقتی عملیات نوشتن واقعا همزمان اتفاق میفته لازمه یه مکانیزم دیگه ای مثل version vector بیاد به کمک تا بشه همزمانی واقعی رو تشخیص بده

این امکان برای دو نود وجود دارد که به طور مستقل رایت هایی را با همان مهر تایم استمپ تولید کنند، به خصوص زمانی که دقت کلاک میلی‌ثانیه دارد. برای حل این گونه conflictها، یک عدد تصادقی بزرگ به عنوان  tiebreaker مورد نیاز است، اما این رویکرد هم می توانه منجر به نقض علیت بشه.

آیا میشه دقت کلاک رو انقدر بالا برد که کمتر به conflict بخوریم؟ نه چون دقت سینک کردن NTP خودش محدود هست به مدت زمان رفت و برگشت در شبکه.

کلاک logical یعنی از یک کانتر استفاده کنیم به جای اینکه از oscillating quartz crystal استفاده بشه. شاید این کلاک منطقی روش بهتری باشه. ازین کلاک میشه برای مشخص کردن ترتیب رخداد ها استفاده کرد. نه برای بدست اوردن زمان و تاریخ.

در وقابل به کلاک هایی که زمان و تاریخ رو میدن کلاک physical میگن.

### Clock readings have a confidence interval

حتی اگر بشه روی ماشین ها کلال رو با دقت بالا مثلا نانوثانیه بدست آورد به معنی این نیست که به همون اندازه دقیق هست. حتی اگر بخواد با یه NTP server روی نتوورک لوکال سینک بشه. روی نتوورک پابلیک هم که مساله ازدحام شبکه و تاخیر و اینا هم بهش اضافه میشه.

با این توضیحات کلاک رو نباید به صورت زمان یک لحظه خوند. باید خطای احتمالی رو در نظر گرفت و به صورت بازه ای بهش نگاه کرد. 

میزان خطا یا همون طول بازه رو سورس کلاک تو سیستم مشخص میکنه. مثلا اگر زمان رو داریم از  گیرنده GPS میگیریم باید ببینیم  manufacturer اون چه میزان احتمال خطا رو اعلام کرده.

اگر داریم تایم رو از یک NTP server میگیریم باید یه پارامترهایی رو درنظر بگیریم. اینکه اولا بازه زمانی بین هر عملیات سینک چقدر هست + میزان خطایی که در خود سرور NTP ممکنه باشه + تاخیر نتوورک به اندازه یه رفت و برگشت به سرور NTP.

متاسفانه هر سیستمی که کلاک رو تامین میکنه این عدم قطعیت و میزان خطا رو اعلام نمیکنه. 

اما سرویس TrueTime گوگل اینطور نیست. قشنگ کلاک رو به صورت بازه ی [earliest, latest] برمیگردونه و همه عوامل موثر در این عدم قطعیت رو در نظر میگیره.

### Synchronized clocks for global snapshots

تو بحث Snapshot Isolation گفتیم که لازمه به تراکنش ها یه آیدی یونیک اختصاص داده بشه. اگر دیتابیس توزیع شده هست این آیدی باید ازنوع
global, monotonically increasing transaction ID
باشد.

اگر تایم سیستم به اندازه کافی سینک باشه میشه ازش به عنوان transaction-id استفاده کرد.
Spanner 
داره snapshot isolation رو به همین روش پیاده سازی میکنه. با استفاده از TrueTime API گوگل .

برای اطمینان ازینکه تقدم و تاخر تراکنش ها خطیی توش نباشه Spanner میاد یه زمانی صبر میکنه بعد تراکنش های read-write رو کامیت میکنه. اینجوری اگر تراکنشی که میخاد داده رو بخونه با یکم تاخیر تایم استمپ خورده باشه با تراکنش نوشتنی همپوشانی نخواهد داشت.

## Process Pauses


دیتابیس تک لیدری رو فرض کنید. در این دیتابیس یه لیدر از کجا میتونه متوجه بشه که هنوز از نظر بقیه نودها لیدر هست. لیدر میاد یه لاک میذاره روی بقیه نودها. لاکی که تایم اوت داره. بهش میگن lease. هر لحظه فقط یه نود میتونه این لاک رو بذاره رو کلاستر. اگر لیدر تونست این لاک رو بذاره میفهمه که هنوز از نظر بقیه ایشون لیدر هست.

برای اینکه لیدر بتونه لیدر بمونه باید مرتب این لاک رو تجدید کنه. اگر لیدر بمیره و دیگه لاک رو تجدید نکنه بقیه میتونن تشخیص بدن که لیدر از چه زمانی زنده نیست دیگه.

یه چیزی شبیه این کد، وقتی به ریکوئست برای نوشتن تو دیتابیس میاد، لیدر چک میکنه که lease تایم اوت شده یا نه، اگر شده سعی میکنه تمدیدش کنه. اگر بتونه تمدید کنه درخواست نوشتن رو قبول میکنه. اگر lease تایم اوت نشده بود هم که یعنی هنوز لیدر هست و درخواست رو قبول میکنه.

یکی از مشکلات این کد اینه که تایم اوت رو از روی زمان ماشین اندازه میگیره درحالی که ممکنه کلاک ماشین سینک نباشه.
دوم اینکه فرض شده از خط 
if (lease.expiryTimeMillis - System.currentTimeMillis() < 10000)
تا خط
process(request);
خیلی زمان کوتاهی هست و ۱۰ ثانیه نمیشه.

ولی فکر کنید بین این دوتا خط thread ۱۵ ثانیه توقف کنه. اینطوری تا این فاطله lease اکسپایر میشه.

همچین فرضی اصلا احمقانه نیست. مثلا فرض کنید تو jvm پروسه GC کارش رو شروع بکنه رسما کل دنیا رو متوقف میکنه تا کارش کامل تموم بشه.

اینجا داره چندتا سناریو دیگه مثال میزنه که میتونن موجب pause شدن thread جاری بشن.

همه اتفقاتی که گفته شد میتونن باعث بشن که thread جاری به صورت preempt پردازنده رو ترک بکنه.
یعنی اون کدی که نوشته شد برای چک کردن تایم اوت روی lease و تمدیدش توسط لیدر باید به صورت thread-safe نوشته بشه.

وقتی میخواهیم یه کد thread-safe بنویسیم که قراره روی یک ماشین واحد اجرا بشه خیلی راحت از ابزارهای هایلایت شده در متن کتاب استفاده میکنیم.

ولی وقتی داریم در مورد سیستم توزیع شده صحبت میکنیم نمیشه این ابزار ها رو تعمیم داد. چون وقتی سیستم توزیع شده هست هیچ حافظه مشترکی بین شون نیست و تنها راه ارتباط شون ارسال مسیج از طریق شبکه unreliable هست.

یک نود در یک سیستم توزیع شده باید بداند که ممکنه هر موقع pause بشه درحالی که بقیه نودها دارن کار میکنن. تازه در این مدت ممکنه بقیه نودها فکر کنند نود pause شده مرده . 

### Response time guarantees

بعضی سیستم ها hard real-time هستن مثل برنامه ای که برای هواپیما یا راکت نوشته میشه. ریسپانس ها به این سرویس ها باید گارانتی داشه باشن.

برای اینکه بشه تو یه سیستم response-time رو گارانتی کرد لازمه تمام لایه های سیستم این موضوع رو پشتیبانی کنند. از cpu گرفته تا تخصیص حافظه و ...

برای همین نوشتن برنامه real-time هزینه داره. برنامه های real-time دیگه throughput, براشون  مهم نیست.

### Limiting the impact of garbage collection

میشه اثرات منفی pause شدن پراسس رو کاهش داد بدون اینکه مجبور بشیم از real-time scheduling استفاده کنیم.

یه ایده نوظهور اینهه که وقتی کلاینت به یه نود درخواست میده درحالی که نود میدونه به زودی قراره به خاطر GC از دسترسی خارج بشه اینطوری اون کلاینت دیگه سما این نود درخواستی نمیفرسته. برخی اپلیکیشن های مالی که latency-sensitive هستند ازین روش استفاده میکنند.

یه شکل دیگه ی این ایده اینطوری هست که از GC فقط برای جارو کردن آبجکت های short-lived استفاده بشه و پراسس ها زود زود ریستارت بشن قبل از اینکه موجب آبجکت های long-lived بشن.
هر نود میتونه در هر زمانی ریستارت بشه و قبلش به کلاینت خبر میده که درخواست های سمتش نیاد. اینجوری مدت زمانی که GC کار انجام میده کوتاه میشه.

## Knowledge, Truth, and Lies
اینجا داره میگه طراحی مسیستم های توزیع شده خیلی چالش داره و ارتباط روی شبکه unreliable هست. کلاک ها unreliable هستن. 
اما در ادامه میگه با این حال روی همین نتوورک هم میشه سیستم رو طوری طراحی کرد که سیستم رفتار reliable روی نتوورک unreliable داشته باشه.

## The Truth Is Defined by the Majority



حقیقت چیزی هست که اکثریت روی ان توافق داشته باشن. 
اگر یه نود توی شبکه میتونه تمام درخواست ها رو بگیره ولی ریسپانس هاش به هیشکی نمیرسه، اکثریت نظرشون اینه که این نود مرده ولی خودش داد میزنه میگه که زندس و کسی نمیشنوه. حقیقت از نظر شبکه اینه که اون مرده چون اکثریت با این موافقن.

در نتیجه در سیستم های توزیع شده معمولا از مکانیزم هایی از جمله quorum استفاده میکنند و برای دانشتن حقیقت بین نود ها رای گیری میکنن.

### The leader and the lock
یه سری چیزا هستن که لازمه تو سیستم یکی ازشون باشه. مثلا لیدر تو دیتابیس باید یکی باشه تا split brain رخ نده. در هر لحظه فقط یه تراکنش میتونه روی یه آبجکت لاک بذاره. فقط یه کاربر میتونه یه یوزرنیم مشخص رو داشته باشه و ...

پیاده سازی این چیز میزا تو سیستم های توزیع شده نیازمند دقت بیشتری هست. حتی اگر یه نود معتقد هست که اون یکی خودشه ممکنه نودهای quorum این نظر رو نداشته باشن.

در این سناریو کلاینت ۱ یه دیتا رو لاک کنه. موفق میشه لاک کنه. بعدش خودش دچار garbage collection میشه و کارش روی دیتا به عقب میفته. در این مدت لاک اون تایم اوت میشه در حالی که خودش خبر نداره. کلاینت تو در این فاصله میاد روی همان دیتا لاک میذاره. اینجا کلاینت ۱ پروسه garbage collection اش تموم میشه و میاد کارش رو با دیتا انجام بده و اونو رایت کنه که با اکسپشن مواجه میشه.

![[Pasted image 20250203153424.png]]

ما لازم داریم مطمئن باشیم که وقتی یه نود به اشتباه فکر میکنه که نوبتش هست که دیتا رو تغییر بده، نتونه دیتا رو خراب کنه. راه حلی این مساله نامش fencing هست.

مکانیزمش اینطوریه که وقتی کلایت از سرور لاک دریافت کرد به همراهش یه توکن به عنوان fencing token هم تحویل میگیره از سرور. این توکن هربار یکی اضافه میشه به مقدارش. 
هربار که کلاینت میره سراغ سرور برای نوشتن دیتا، باید این توکن رو تحویل سرور بده. اگر مقدار توکن از current fencing token کمتر باشه خطای old token به کلاینت برمیگرده.

![[Pasted image 20250203153443.png]]


## Byzantine Faults



با Fencing tokens میشه نودهایی که ناخواسته اشتباه عمل میکنند رو شناسایی و لاک شون کرد. مثلا نودی که خبر نداره که lease اش اکسپایر شده و همچنان داره با همون lease دیتا رو تغییر میده.

ولی یه نود اگر بخواد از قصد خرابکاری بکنه میتونه یه fake fencing token کارش رو انجام بده.

در این کتاب ما فرض میکنیم که ممکنه نودهامون unreliable باشند  ولی صادق هستند و نیت خرابکاری ندارند.

مشکلات سیستم های توزیع شده وقتی خیلی حاد میشه که نودها به قصد خرابکاری دروغ بگن. مثلا یه نود ادعا میکنه یه مسیج به خصوصی رو دریافت کرده در حالی که واقعا دریافت نکرده. به همچین رفتاری میگن Byzantine fault. مساله رسیدن به یک اجماعی در این محیط untrust معروف هست به Byzantine Generals Problem.


وقتی به یک سیستم میگن Byzantine fault-tolerant که بتونه کارش رو به درستی انجام بده با وجود نودهای خرابکار. این نگرانی در برخی سیستم ها خیلی حیاتی تر هست.
مثلا در یک محیط هوافضا یه خرابکاری ممکنه عواقب خیلی بدی داشته باشه.
یا مثلا در شبکه بیت کوین هم Byzantine fault-tolerant بودن خیلی مهم هست.

اما وقتی در مورد تمام نودهاتون مال سازمان خودتون هست دیگه نگران Byzantine fault نیستین.

از طرفی خیلی کار ساده ای نیست که یک سیستم رو بتونیم Byzantine fault-tolerant بکنیم. 

توی اپلیکیشن های وب که کلاینت شون همون کاربران هستند که از طریق web browser سرویس میگیرند، خیلی احتمال داره توسط کاربران بدخواه دچار حمله بشن که برای پیشگیری از چنین حملاتی از تکنیک هایی مثل input validation و authentication و غیره استفاده میکنند. به این مکانیزم های محافظت Byzantine fault-tolerant نمیگن!!

موضوع Byzantine fault-tolerant به سیستم های peer-to-peer مطرح میشه که مثلا نمیشه یه authority مرکزی داشته باشیم.

الگوریتم های Byzantine fault-tolerant وقتی عمل میکنند که حداقل دو سوم نودهامون سالم باشن. اگر قراره همشون خرابکار باشند این الگوریتم ها قادر به اصلاح خرابکاری نیستن.

از طرفی Byzantine fault-tolerant algorithm در مقابل حملات مخرب و vulnerability ها هم جواب نمیده. چون اگر یه attacker تونسته به یک نود آسیب بزنه حتما به بقیه نودها هم میتونه. چون معمولا همه نودها یه software یکسان روشون اجرا شده.

### Weak forms of lying

با اینکه ما فرض مون اینه که نودهامون نیت بدی ندارن اما بد نیست که یه سری مکانیزم به سیستم اضافه کنیم که سیستم رو در مقابل Weak forms of lying محافظت کنه.
با این مکانیزم ها که نمیشه گفت به طور کامل  Byzantine fault tolerance داریم تو سیستم چون این مکانیزم ها در برابر نودهای خرابکار مصمم محافظتی ایجاد نمیکنن. اما در کل بودنشون قابلیت اعتماد رو در سیستم افزایش میده.

مثل Network packet ها که ممکنه بر اثر مسائل سخت افزاری دچار خرابی بشن. میشه با مکانیزم checksum این مشکل رو تشخیص داد.

یا مثلا اپلیکیشن هایی که قابل استفاده برای عموم هستن باید تمام input کاربر ها را چک کرد و محدودیت های مناسبی براشون تنظیم کرد.


## System Model and Reality



