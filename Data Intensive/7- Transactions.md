هر آن ممکنه خود دیتابیس وسط کار خراب بشه، اپلیکیشن کرش کنه، نتوورک دچار مشکل بشه، کلاینت ها همزمان بخوان یه دیتا رو تغییر بدن و ...
سیستم باید در مقابل همه این مشکلات احتمالی fault tollerant باشه.
برای چندین دهه transactions راه حلی برای این مشکلات احتمالی بودن. 
اگر سال هاست داریم با transactions کار میکنیم ممکنه خیلی بهشون سطحی نگاه کنیم و حواسمون نباشه که چه کمکی به ما میکنند در پیاده سازی اپلیکیشن ها. 
البته هر اپلیکیشنی بیاز به transactions نداره یا ممکنه براش خوب باشه که از transactions استفاده نکنه. مثلا وقتی که میتونه بدون استفاده از transactions پرفورمنس یا availability بالاتری داشته باشه.
شما چطورم یتونی تشخیص بدی که آیا به transactions نیاز داری یا نه؟ برای پاسخ به این سوال ما نیاز داریم اول بدونیم transactions چه قابلیت هایی به ما میدن و در مقابل چه هزینه هایی برای ما دارن؟ و اینکه در نگاه اول transactions خیلی ساده و سرراست به نظر میان ولی خیلی جزئیات ظریفی دارن که باید بدونیم.

تو این فصل قراره در مورد کلیه مباحث حول transactions صحبت کنیم.

# The Slippery Concept of a Transaction

امروزه خیلی از دیتابیس های relational و حتی برخی از nonrelational ها از transactions پشتیبانی میکنند. اغلب هم از همون تعریف و استایلی استفاده میکنند کهع اولین بار در سال ۱۹۷۵ توسط IBM تعریف شد.
در سال ۲۰۰۰ دیتابیس های nonrelational محبوب شدند. هدف اونها معرفی کردن دیتامدل جدید در کنار رپلیکیشن و پارتیشنینگ بود. بحث Transactions برای اونها مزاحمت به حساب میومدن در نتیجه این نسل جدید از دیتابیس ها کلا Transactions را کنار گذاشتند.
با هیاهوی این دیتابیس های توزیع شده، این باور عمومی شکل گرفت Transactions با scalability, منافات دارن و هر سیستم در مقیاس بزرگ باید scalability, را به منظور حفظ performance و availabilityا کنار بگذارد.
بریم ببینیم transactions چه خوبی و بدی هایی دارند.

# The Meaning of ACID
ویژگی transactions معمولا با کلمه ACID شرح داده میشه:
ACID : Atomicity, Consistency, Isolation, Durability

در عمل پیاده سازی خواص ACID توسط دیتابیس های مختلف متفاوت هست. برای همین وقتی یک دیتابیس ادعا میکنه که خاصیت ACID داره نمیشه گفت دقیقا چیارو گارانتی میکنه.

دیتاسیستمی که خاصیت ACID نداره گاها BASE می نامند یعنی:
Basically Available, Soft state, Eventual consistency


## Atomicity
Atomicity
یعنی چیزی که نمیشه بشکنیمش به بخش های کپچیک تر.
مثلا در برنامه multi-threaded  که یکی از threaded ها داره چندتا کار به صورت Atomic انجام میده، هرگز یک thread دیگه نمیتونه نتایج نیمه کاره ترد مورد نظر رو ببینه. 

البته در موضوع ACID برای تعریف Atomicity اصلا به concurrency. اشاره نمیشه. در این بحث Atomicity میگه وقتی یک کلاینت چندتا دیتا رو میخواد به صورت Atomic بنویسه اگر در وسط این عملیات هر مشکلی پیش بیاد transaction نمیتونه کامل (کامیت‌) بشه بلکه aborted میشه و اون چندتا دیتای کلاینت باید رول بک بشن. 
بدون atomicity اگر وسط چندتا عمل atomic یه مشکلی پیش میامد نمیدونستیم دقیقا چه تغییراتی اعمال شده و باید discard بشن. 

میشه گفت یه واژه معادل برای اتومیسیتی ، abortability هست.
## Consistency

Consistency
در جاهای متفاوتی استفاده شده که معنایش در هر مورد تقاوت های ظریفی با هم داره

در بحث رپلیکیشن موضوع eventual consistency رو داشتیم
در بحث پارتیشنینگ برای پارتیشن بندی با هش کلید بحث Consistent hashing بود
در تئوری CAP (مربوط به فصل ۹) اونو به معنی linearizability خواهیم داشت
و در بحث تراکنش ها و خاصیت ACID معنای دیگه ای میده. 

consistency
در بحث ACID یعنی دیتاهای ما که در دیتابیس قرار دارند باید همیشه در وصعیت خوبی قرار داشته باشند. این وضعیت خوب متناسب با هر اپلیکیشنی تعریف می شود. 
مثلا اگر مبلغی قرار هست بین دوتا اکانت جابه جا شود، باید مجموع موجودی آن دو اکانت قبل و بعد از تراکنش یکسان باشد.



البته در مورد consistency این اپلیکیشن هست که باید بتواند transaction های درستی تعریف کند . در این زمینه دیتابیس هیچ تضمینی نمیده. در حالی که اون سه خاصیت دیگه یعنی Atomicity, isolation, and durability رو دیتابیس داره فراهم میکنه.

## Isolation

اگر همزمان دوتا کلاینت بخواهند یک رکورد رو تغییر بدهند مسال هrace conditions رخ میده.
شکل ۷-۱ داره یه مساله race conditions رو نشون میده.
در موضوع ACID مورد Isolation اینو میگه که تراکنش های موازی از هم ایزوله هستن.
در تعاریف کلاسیک به این ویژگی serializability هم میگفتن. چون وقتی transaction ها اجرا و کامیت میشن نتیجه نهایی طوری هست که انگار transaction ها کاملا به طور سریالی و متوالی اجرا شدند. با اینکه در حقیقت موازی اجزا شدند نه متوالی.

![[Pasted image 20241007133617.png]]

serializable isolation
به ندرت استفاده میشه چون خیلی پرفورمنس رو کاهش میده.
مثلا اوراکس اصلا همچین خاصیتی رو پیاده سازی نکرده. اوراکل یه مدل آیزوبیشن داره به نام serializable ولی در حقیقت داره اونو به روش snapshot isolation پیاده سازی میکنه. در ادامه جزئیاتشو میبینیم.

## Durability
Durability
میگه دیتابیس قول میده که وقتی یک transaction با موفقیت کامیت شد، هر دیتایی که آن نوشته است ماندگار میشه و دیگه نگران از بین رفتن آن دیتا نباشید.
وقتی دیتابیس سینگل نود هست، Durability یعنی دیتای کامیت شده روی یک استوریج غیر فرار مثل هارد نوشته شده.
وقتی دیتابیس رپلیکیشن دارد، Durability یعنی دیتا با موفقیت روی تمام نودها کپی شده است.

واقع بینانه نگاه کنیم ما Durability پرفکت نداریم چون اگر به هر دلیلی تمام کپی های دیتا از بین بروند دیتا از دست رفته است. درواقع داریم یه سری تکنیک ها با هدف risk-reduction به کار میگیریم.

# Single-Object and Multi-Object Operations
اینجا هم باز به تکرار دو موضوع isolation و atomicity رو توضیح میده.

اگر کلاینت در قالب یه تراکنش میخواهد چندین رکورد از دیتابیس رو تغییر بده مربوط میشه به موضوع Multi-Object Operations.
شکل ۷-۲ مربوط به یک اپلیکیشن ایمیل هست. تعداد ایمیل های ناخوانده کاربر با این کوئری که در این پاراگراف هست شمرده میشه.

در این شکل کاربر ۱ یک ایمیل به کار ۲ میده. برای این کار دوتا دیتا در دیتابیس درج میشه. یکی آبجکت ایمیل که در تیبل emails اضافه میشه و دیگری ++ کردن unread counter که در تیبل mailboxes درج میشه. ولی چون اینجا خاصیت isolation نداشتیم وسط این دوتا عمل، کاربر ۲ اومد و ایمیل رو در اینباکس خودش دید در عین حال unread counter رو صفر مشاهده کرد. در واقع کاربر ۲ در این سناریو ا انومالی dirty read مواجه شد. او تونست تغییرات کاربر ۱ را بدون اینکه عملیاتش به طور کامل تمام شود مشاهده کند.


![[Pasted image 20241007133714.png]]

![[Pasted image 20241007133725.png]]

در شکل ۷-۳ داره نیاز به atomicity رو نشون میده. اگر هرجایی از این تراکنش مولتی آبجکت عملیات موفق نباشد هردوی آنها باید رول بک شوند.

در تراکنش های مولتی آبجکت باید بتونیم عملیات خواندن و نوشتنی که متعلق به یک تراکنش هستند را تشخیص بدیم.

در دیتابیس های رابطه ای این کار معمولا از روی کانکشن TCP  کلاینت شناسایی میشه.  روی هر کانکشنی کلیه عملیاتی که مابین BEGIN TRANSACTION  و COMMIT انجام میشن متعلق به یک تراکنش هستند.

بسیاری از دیتابیس های غیر رابطه ای  راهی ندارند که بخوان عملیات دیتابیسی را به هم گروپ کنند. حتی اگر یک API از نوع مولتی آبجکت باشه هم نیاز نیست اونها در قالب تراکنش محسوب بشن.

## Single-object writes

نوشتن های سینگل آبجکت:
حتی وقتی یک تراکنش از نوع سینگل آبجکت هست هم نیاز به خاصیت های Atomicity و isolation وجود داره. مثلا فرض کنید تراکنش نوشتن یک داکیومنت ۲۰ کیلوبایتی می باشد.

اگر وسط نوشتن دیتای ۲۰ کیلوبایتی مشکل شبکه ای یا مشکل دیتابیسی پیش بیاد چکار باید کرد؟ 

چون این مسائل خیلی پیچیده هستن، اغلب دیتابیس ها میان atomicity و isolation رو فقط روی سینگل آبجکت و روی یک نود فراهم میکنند. atomicity رو میان با کمک log برای مواقع ریکاوری کردن crash فراهم میکنند و isolation را با lock کردن هر آبجکت.


برخی دیتابیس ها هم میان عملیات اتومیک پیچیده ای رو اراسه میدن. مثلا از عمل پلاس پلاس پشتیبانی میکنند.  دیگه اینجوری نیازی نیست که برای increment سیکل read-modify-write انجام بشه. مشابه همین عملیات compare-and-set هم هست که برخی دیتابیس ها پشتیبانیش میکنند.
این عملیات چون سینگل آبجکت هستن رو میشه به عنوان light‐weight transactions هم دانست.

## The need for multi-object transactions
 خیلی از دیتابیس های توزیع شده کلا تراکنش های مولتی آبجکت رو پشتیبانی نمیکنند چون پیاده سازیش پیچیدس و اینکه این پیچیدگی ها با availability و performance منافات دارند. ولی در کل مانع خاصی وجود نداره که نشه در حالت توزیع شده تراکنش ها رو هم پشتیبانی کرد. در فصل ۹ transaction های توزیع شده رو خواهیم دید.
آیا اصلا ما نیازی به تراکنش های مولتی آبجکت داریم؟ ایا میشه هر اپلیکیشنی را با دیتا مدل key-value  و عملیات سینگل آبجکتی پیاده سازی کرد؟
در دیتابیس های رابطه ای یک رکورد معمولا foreigh-key داره به یک رکورد دیگر در تیبل دیگر. تراکنش های مولتی آبجکت این تضمین رو به شما میده که این رفرنس ها خراب نشن.در دیتامدل های داکیومنتی رابطه جوین بین داکیومنت ها ندارند. داکیومنت های به صورت سینگل آبجکت آپدیت میشن. هرچند گاهی داکیومنت ها نرمالایز شده نیستن و redundancy  داریم و یه آپدیت روی یک داکیومنت لازم داره یه جای دیگه یه داکیومنت دیگه هم آپدیت بشه. در این شرایط هم Transaction ها میتونن کمک کننده باشن.

در دیتابیس هایی که secondary index دارند هم وقتی رکوردی آپدیت میشه لازمه ایندکس های ثانویه هم اپدیت بشن. اینجا هم نیاز به وجود transaction داریم که آپدیت ایندکس ها حتما به همراه آپدیت رکورد اصلی انجام بشه.

## Handling errors and aborts
ویژگی ACID تراکنش ها باعث میشه وقتی مشکلی پیش میاد عملیات ان تراکنش به طور کامل abort بشه و بشه با خیال راحت اونو از اول تکرار کرد.
همه دیتابیس ها از قانون ACID پیروی نمیکنند. به خصوص دیتابیس های رپلیکیشن شده به روش بدون لیدر بر اساس best effor کار میکنند. یعنی دیتابیس تمام تلاش خودشو میکنه که هم هچیز درست پیش بره ولی اگر مشکلی پیش بیاد هیچ کاری در راستای UNDO کردن انجام نمیده. در نتیجه خود اپلیکیشن باید خطا رو ریکاور کنه.
خطا اجتناب ناپذیره اما دولوپرها ترجیح میدن همیشه فکر کنن اپلیکیشن قراره روی هپی ترین مسیر حرکت کنه. برخی از ORM ها مثل اونایی که هایلایت شدن نمیان تراکنش های abort  شده رو دوباره تکرار کنن بلکه میان یه اکسپشن به لایه بالاتر پرتاب میکنن. 
هرچند تکرار دوباره تراکنش abortشده میتونه یه روش error handling باشه اما نه همیشه. در موارد زیر تکرار تراکنش abort شده راه حل درستی نیست.

- فرض کنید تراکنش به درستی انجام شده ولی به دلیل مشکل شبکه ای اپلیکیشن فکر میکند تراکنش abort شده
- اگر دیتابیس overload شده و برای همین نتونسته تراکنش رو انجام بده. تکرارش اوضاع رو بدتر میکنه
- گاهی تکرار تراکنش مشکل رو حل نمیکنه چون علت abort شدن تراکنش یه مساله permanent هست 
- اگر تراکنش یه side-effect خارج از دیتابیس داشته باشه ثلا در میانه تراکنش ایمیلی به کلاینت ارسال میشه. تکرار تراکنش abort شده باعث ارسال ایمیل تکراری میشه. اینجا بحث Two Phase Commint مطرح میشه که در صفحه ۳۵۴ قراره در موردش صحبت بشه


# Weak Isolation Levels
چون پیشگیری از race condition سمت اپلیکیشن و توسط دولوپری کار راحتی نیست و خیلی قابل تست نیست در نتیجه دیتابیس ها سعی میکنند این مساله را خودشان هندل کنند. قوی ترین سطح isolation در دیتابیس حالت serializable هست ولی چون هزینه پرفورمنسی بالایی دارد خیلی دیتابیس ها زیر بارش نمیرن. به جاش میان از متدهای ظعیف تر isolation استفاده میکنند. این روش های ضعیف تر بسیار امکان خطا و خراب شدن داده دارند در نتیجه اگر اپلیکیشن مالی دارین بهتره از دیتابیس های رابطه ای استفاده کنید.

در ادامه به چندتا از روش های Weak Isolation اشاره خواهد شد.

# Read Committed
Read Committed
این متد گارانتی میکنه که:
- شما هنگام خوندن از دیتابیس، فقط تغییرات کامیت شده را روی دیتابیس مشاهده خواهید کرد. امکان dirty reads نداریم.
- شما هنگام نوشتن روی دیتابیس فقط قادر خواهید بود دیتاهایی رو بنویسید که تا اون لحظه کامیت شده اند. امکان dirty writes نداریم.
.
در این شکل تا زمانی که کاربر ۱ کامیت نکده اثر تراکنشش توسط کاربر ۲ مشاهده نمیشود.
![[Pasted image 20241007134051.png]]

اینجا داره توضیح میده که چرا dirty read بد هست.

## No dirty writes
وقتی دو تا تراکنش همزمان میخوان یه دیتا رو تغییر بدن:
اولی وسط تراکنش هست و هنوز کامیت نکرده، دومی بیاد و تغییرات کامیت نشده اولی رو overwrite کنه (dirty write). وقتی دیتابیس قابلیت read committed isolation داره در این سناریو اجازه نمیده تراکنش دوم دیتا بنویسه تا زمانی که تراکنش اول یا کامیت بشه یا abort. 
در شکل ۷-۱ هم که دوتا کلاینت همزمان میخواستن یه دیتا رو پلاس پلاس کنند. در اون شرایط با داشتن read committed مشکل حل نمیشه. در مبحث Preventing Lost Updates به موضوع counter increments safe خواهیم پرداخت.

دو نفر همزمان میخواست یه ماشین رو بخرن. چون احتمال dirty write وجو داشت در نهایت خریدار ماشین در دیتابیس به نام Bob خورده ولی صورت حساب به نام Alice صادر شده است.

![[Pasted image 20241007134208.png]]

## Implementing read committed
read committed
خیلی بیسیک هست و خیلیا پیاده سازیش کردن.
Oracle11g, PostgreSQL, SQL Server 2012, MemSQL,

اغلب دیتابیس ها برای پیاده سازی read committed از روش row-level locks استفاده میکنند. وقتی یک تراکنش میخواهد یک آبجکت رو تغییر بده اونو لاک میکنه. تا وقتی این لاک آزاد نشده هیچ تراکنش دیگری نمیتونه روی ان آبجکت لاک بذاره.

 یه روش برای جلوگیری از dirty read این هست که وقتی تراکنشی میخواد یک آبجکت رو بخونه روی اون لاک بذاره تا در اون مدت تراکنش دیگه ای نتونه اون آبجکت رو تغییر بده.

اما لاک کردن دیتا موقع خوندنش خیلی روش بهینه ای نیست. چون وقتی یه تراکنشی داره دیتا مینویسه تمام عملیات خواندن باید منتظرش باشند. 

 در نتیجه بیشتر دیتابیس های برای جلوگیری از dirty read از روشی که در شکل ۷-۴ دیدم استفاده میکنند. وقتی یه تراکنشی در حال تغییر یه آبجکتی هست و هنوز کامیت نکرده هر تراکنشی بخواهد ان دیتا را بخواند مقدار old اون رو خواهد خوند.

# Snapshot Isolation and Repeatable Read

هنوز ایشیوهای زیادی هستن که با read committed isolation حل نشده اند و باید فکری برایشان بکنیم، مثل شکل ۷-۶.
آلیس در مجموع ۱۰۰۰ دلار موجودی داره که ۵۰۰ تاش در اکانت ۱ و ۵۰۰ تاش در اکانت ۲ قرار داره.
آلیس از اکانت ۱ مانده میگیره و میبینه ۵۰۰ تا موجودی داره.
میاد از اکانت دوم موجودی بگیره میبینه ۴۰۰ تا موجودی داره. چون:
اون وسط یه تراکنش انجام شده که ۱۰۰ تا از اکانت ۲ به اکانت ۱ منتقل کرده.
آلیس که ازون تارکنش خبر نداره. براش سوال پیش میاد که چرا مجموع موجودی دو اکانتش ۱۰۰۰ دلار نیست؟
به این آنومالی میگن nonrepeatable read یا read skew.


![[Pasted image 20241007134307.png]]

این مشکلی که آلیس مشاهده میکند یک مشکل موندگار نیست. چون اگر دوباره برگرده از امانت ۱ موجودی بگیره میبینه موجودیش شده ۶۰۰تا. اما با این حال در برخی شرایط نمیخواهیم این آنومالی را در اپلیکیشن خودمون داشته باشیم.
از جمله اون موقعی که نمیخواهیم این آنومالی رو داشته باشیم موقع بک آپ گرفتن هست. ممکنه پروسه بک آپ گرفتن مدت زمان زیادی طول بکشه و در اون مدت دیتاها توسط کلاینت تغییر کنند. یه بخشی از بک آپ تغییرات به روز رو نداره. برخیش داره. حالا اگر ما بعدا اون بک آپ رو restore کنیم دیتامون inconsistent خواهد بود.
یا موقعی که شما دارین با یه کوئری کل دیتاتون رو اسکن میکنین ممکنه در حین اسکن دیتا توسط کلاینت یه تغییراتی بکنه که کوئری شما اون تغییرات رو متوجه نشه. دیتاهای اسکن شده تون یه بخشیش قدیمی و یه بخشیش تازه باشه. 
راه حل این آنومالی ها Snapshot isolation هست. ایده این راه حل اینه که وقتی یه تراکنشی میخواهد یه دیتایی رو بخواند اونو از consistent snapshot بخواند. یعنی هرچیزی که تا اون لحظه کامیت شده است رو بتونه ببینه.
این آنومالی ها معمولا در کوئری های read-only که long-running هستند دیده میشه که وسط اجرای کويری دیتا عوض بشه. این راه حل میگه این کوئری ها دیتاشون رو از یک اسنپ شات consistent بخونن.
این روش در بسیاری از دیتابیس ها از جمله اونایی که در متن کتاب هایلایت شدند استفاده میشه.

## Implementing snapshot isolation
اینجا هم دقیقا مانند read committed isolation جلوی انومالی dirty write گرفته میشه. وقتی تراکنشی میخواهد دیتا بنویسد آبجکت را لاک میکند تا تراکنش دیگر نتواند روی آن بنویسد. اینجا هم مثل آنجا اجازه نمیدیم تراکنش های نوشتی بتوانند تراکنش های خواندنی را بلاک کنند و برعکس. 
در روش read committed isolation کافی بود دوتا اسنپ شات از دیتا داشته باشیم. یکی که تمام تغییرات کامیت شده را دارد و دیگری که تغییرات کامیت نشده یک تراکنش را دارد.

اما برای پیاده سازی snapshot isolation لازمه تعداد اسنپ شات بیشتری از دیتامون داشته باشیم. به این تکنیک میگن multi-version concurrency control.

پیاده سازی روش multi-version concurrency control در دیتابیس Postgresql  در شکل ۷-۷ دیده میشه.


![[Pasted image 20241007134408.png]]

هر وقت یه تراکنش شروع میشه یه یونیک آیدی بهش اختصاص داده میشه. این آیدی ها هم always-increasing هستن.
وقتی یه تراکنش دیتایی روی دیتابیس مینویسه. دیتای نوشته شده تگ میخوره روش، آید تراکنش میخوره روی دیتا.
هر رکوردی توی دیتابیس دوتا ستون اضافه تر هم دارند created_by و deleted_by.
فیلد created_by آیدی تراکنشی رو نگه میداره که اون رکورد رو درج کرده در دیتابیس.
فیلد deleted_by که در ابتدا نال هست. هر زمان تراکنشی اون رکورد رو دیلیت کنه آیدی در این فیلد تگ میشه.
بعدش garbage collection میاد تمام رکوردهایی که تگ دیلیت خودن رو دور میریزه.

یک عمل آیدیت کردن روی یک رکورد به صورت یک دیلیت و یک درج یا create در میاد. در شکل بالا وقتی تراکنش ۱۳  میخواد ۱۰۰ دلار از اکانت ۲ کم کنه و مانده اون حساب رو از ۵۰۰ به ۴۰۰ برسونه روی اکانت ۲ یه تگ دیلیت با آیدی ۱۳ و یه تگ ایجاد با آیدی ۱۳ و دیلیت نال اضافه میشه.

## Visibility rules for observing a consistent snapshot

حالا وقتی این همه اسنپ شات مختلف روی دیتامون داریم، وقتی تراکنشی میخاد دیتا بخونه چی رو میخونه دقیقا؟ 

وقتی یه تراکنش میخواد دیتا بخونه یه سری از این اسنپ شات ها رو کلا نمیبینه:
۱- اون اسنپ شات هایی که کامیت نشدن یا هنوز  abort نشدن رو نمیبیه.
۲- تمام تگ هایی که تراکنش هاشون abort شدن را هم نمیبینه.
۳- هر اسنپ شاتی که آیدی بالاتری نسبه به تراکنش جاری خورده هم ایگنور میشن
۴- بقیه هرچی موند توسط تراکنش دیده و خونده میشه.

حالا اگر با این قوانین برگردیم به شکل ۷-۷:
وقتی تراکنش ۱۲ میخواهد اکانت ۲ را بخواند روی ان سه تا تگ میبینه:
 1- توسط آیدی ۵ به وجود آمده  و دیلیت ان نال است و موجودی ۵۰۰ است.
2- توسط آیدی ۵ به وجود آمده و توسط آیدی ۱۳ دیلیت شده و موجودی ۵۰۰ است.
3- توسط آیدی ۱۳ به وجود آمده و دیلیت آن نال است و موجودی ۴۰۰ است.

تگ های ۲ و ۳ رو کلا ایکنور میکنه چون ایدی تراکنش شون ۱۳ هست و از آیدی خودش بالاتر هستن. میمونه تگ ۱ و درنتیجه موجودی رو ۵۰۰ میبینه.

## Indexes and snapshot isolation

ایندکس در دیتابیس مولتی ورژن چگونه عمل میکند؟ یه آپشن اینه که ایندکس به کلیه ورژن های آبجکت های مربوطه اشاره میکند و یه کوئری فیلتر هم داریم که از بین کلیه ورژن های اشاره شده اونهایی که برای کوئری کاربر visibleهستن رو مشخص میکنه. هروقت GC میاد ورژن های قدیمی رو پاک کنه باید این لیستی که هر ایندکس نگه میدارن هم به روز بشه.

درین رابطه پیاده سازی های مختلفی وجود دارد. در متن کتاب هایلایت شدن.

## Repeatable read and naming confusion
Snapshot isolation
در برخی از دیتابیس ها با نامی متفاوت پیاده سازی شده، مثلا اوراکل همین روش رو به نام serializable پیاده سازی کرده، PostgreSQL و MySQL اونو با عنوان repeatable read پیاده کردن.
دلیل این نام های مختلف گیج کننده هم اینه که استاندارد SQL همچین سولوشنی رو تعریف نکرده است.  

# Preventing Lost Updates
دوتا مکانیزم read committed و snapshot isolation برای حل آنومالی تراکنش های خوندنی در مقابل تراکنش های نوشتنی بودند.

یه آنومالی دیگه همزمانی چندین تراکنشی نوشتی باهم هست. قبلا هم تحت عنوان dirty writes بهشون اشاره کردیم. یکی از مشکلاتی که در این همزمانی ممکنه رخ بده lost update هست. در شکل ۷-۱ هم دیدیم که همزمان دوتا کلاینت میخواستن یه متغیر رو پلاس پلاس کنند ولی به دلیل همزمانی تاثیر یکی شون پرید.

مشکل lost update وقتی پیش میاد که دوتا تراکنش همزمان دارن روی یک دیتای مشترک read-modify-write انجام میدن. برای نمونه در سناریوهای زیر:
- Incrementing a counter
- increase | decrease an account balance
- add item to a list field inside json document
- Two users editing a wiki page at the same time


## Atomic write operations

برخی از دیتابیس ها سیکل read-modify-write رو در قالب یه عمل اتومیک پیاده سازی میکنند. مثلا روی این دیتابیس ها میشه کوئری زیر رو اجرا کرد
UPDATE counters SET value = value + 1 WHERE key = 'foo';

در دیتابیس های مبتنی بر داکیومنت مثل مونگودیبی هم همچین مکانیزی پیاده شده. 
ردیس هم همچین مکانیزی پیاده کرده.
دیتابیس ها این کار رو با گذاشتن exclusive lock روی آن دیتا انجام میدن. با exclusive lock حتی تراکنشی نمیتونه اون دیتا رو بخونه حتی. چه برسه که بخواهد بنویسد. این تکنیک به cursor stability معروف هست.
همه عملیات read-modify-write  قابلیت پیاده سازی به صورت اتومیک ندارن. مثل همون ادیت کردن یک متن. چون باید توسط کاربر خونده و سپس ادیت بشه.

ولی اگر شما بیای روی دیتابیس های رابطه ای عملیات read-modify-write رو به صورت unsafe انجام بدی و نیای از قابلیت atomic operations دیتابیس استفاده کنی ممکنه مشکل ایجاد بشه


## Explicit locking

یک روش دیگه استفاده کردن از قابلیت Explicit locking دیتابیس هست. اجازه میده دولوپر از طریق اپلیکیشن رکورد رو لاک کنه و عملیات read-modify-write رو انجام بده و بعد لاک رو آزاد کنه.

## Automatically detecting lost updates

یه راه حل دیگه اینه که سعی نکنیم از وقوع lost update پیشگیری کنیم بلکه اجازه بدیم انجام بده و اگر دیتابیس وقوعش رو تشخیص داد تراکنش را abort کنه.
مزیت این رویکرد اینه که دیتابیس میتونه این موضوع رو بهتر تشخیص بده. برخی از دیتابیس ها مثل PostgreSQL و Oracle و SQL Server با وجود اینکه دارن از مکانیزم های پیشگیری استفاده میکنن این قابلیت تشخیص lost update رو هم دارن. اما مثلا MySQL/ InnoDB همچین قابلیتی برای تشخیص ندارن.
روش Lost update detection خیلی روش خوبیه چون اصلا لازم نیست اپلیکیشن از قابلیت خاصی از دیتابیس استفاده بکنه یا بخواد explicit lock بذاره.

## Compare-and-set

در دیتابیس هایی که اصلا از تراکنش ها پشتیبانی نمیکنند هم گاهی دیده میشه دیتابیس میاد قابلیت Compare-and-set رو خودش پیاده سازی میکنه. مثلا روی همچین دیتابیسی میشه همچین کوئری رو اجرا کرد:
UPDATE wiki_pages SET content = 'new content'
WHERE id = 1234 AND content = 'old content';

## Conflict resolution and replication
در دیتابیس های replicated جلوگیری از مشکل lost updates یکم پیچیدگی داره. چون دیتا چندین کپی روی نودها مختلف داره و ممکنه به طورهمزمان روی نودهای مختلف تغییر بکنه.

متدهای Compare-and-set و atomic read-modify-write مال وقتی هست که رپلیکیشن نداریم. 
وقتی رپلیکیشن به روش multi-leader یا leaderless داریم چون همزمان چندتا نوشتن باهم اتفاق میفته نمیشه گارانتی داد. در نتیجه در این موارد لاک کردن و اینا جواب نمیده.

تو این دیتابیس ها میان اجازه میدن مه نوشتن های همزمان روی رپلیکیشن های مختلف انجام بشه مه نهایتا یه سری conflicting versions ایجاد مشن که باید به روش هایی resolve و مرج بشن. مثلا دیتابیس Riak یه طوری اوتوماتیک کانفلیک هی رو ریزالو میکنه که در نهایت هیچ دیتایی lost نشه.

last write wins (LWW)
یه روشی برای ریزالو کردن کانفلیکت ها هست. در اغلب دیتابیس ها هم روش دیفالت هست.

# Write Skew and Phantoms

غیر از dirty writes و lost updates آنومالی های دیگری هم ممکنه در شرایط race condition اتفاق بیفته.

اینجا داره یه اپلیکیشن برای مدیریت شیفت پزشکان در بیمارستان رو توضیح میده. هر شب بیمارستان حداقل یک یا چند پزشک شیفت باید داشته بشه. هر پزشک متونه شیفتی که براش ست شده رو لغو کنه. اما باید حتما یکی از همکاراش برای اون شیفت حاضر باشه تا ایشون بتونه لغو کنه. درنتیجه در کوئری ها شرط اینکه on-call بزرگتر مساوی ۲ باشد امده است.
فرض کنید برای یه شب آلیس و باب شیفت هستن. هردو هم میخوان لغو کنن. این کار رو هم کاملا همزمان دارن انجام میده.
اگر درست هندل نشه اون شب بیمارستان بدون پزشک on-call خواهد موند.

این آنومالی نه dirty write حساب میشه و نه lost update، بلکه بهش میگن write skew. چون این دوتا آپدیت روی دوتا آبجکت مختلف انجام شده. 

![[Pasted image 20241007134750.png]]**

**
برای کنترل همچین محدودیتی بین چندین آبجکت میشه روی دیتابیس constraint کانفیگ کرد که خود دیتابیس کنترلش کنه. البته به شرطی که دیتابیس همچین قابلیتی داشته باشه.

اینجوری با explicit lock میتونیم مانع ازین بشیم که دوتا دکتر همزمان اون کوئری اول  یعنی 
SELECT * FROM doctors
WHERE on_call = true
AND shift_id = 1234 ;

 رو همزمان اجرا کنند.

## More examples of write skew
اپلیکیشن ای برای مدیریت رزرو اتاق جلسه
توی یک بازی برای اینکه دوتا بازیکن همزمان نخوان به یک پوزیشن یکسان جابه جا بشن.

چون یوزرنیم باید یونیک باشه، اگر دوتا کاربر کاملا همزمان بیان ثبت نام کنن و هردو یوزرنیم یکسانی انتخاب کنند.

در یه اپلیکیشن هر کاربری یه موجودی داره. به شرطی میتونه خرج کنه که موجودی داشته باشه. فرض کنید یه کاربر به طور همزمان دوتا خرجی براش درج بشه. درحالی که مجموع اون دوتا خرجی از موجودی بیشتر هست. اما چون هردو همزمان دارن موجودی رو چک میکنن هرود به این نتیج همیرسن که اجازه دارن خرج کنن. 

## Phantoms causing write skew


در همه این مثال ها یه الگوی مشابه وجود داره:
۱- اول یه کوئری select انجام میشه تا یه شرطی چک بشه
۲- با توجه به نتیجه اون select، اپلیکیشن تصیم میگیره آیا عمل بعدی (کهمیتونه درج یا آپدیت یا حذف باشه) رو انجام بده یا نده.
اون عمل دوم که انجام میشه در واقع روی نتیجه اون precondition اولیه موثر هست. یعنی اگر اون عمل اصلی انجام بشه و دوباره اون شرط اولیه چک بشه ممکنه اینبار نتیجه متفاوتی حاصل بشه.

حتی میشه ترتیب مرحله یک و دو رو تغییر داد. اول عمل اصلی انجام بشه. بعد شرط چک بشه. اگر برقرار نبود عمل اصلی abort بشه.

مثلا در همون مثال دکتر اگر اون چک کردن شرط اولیه به همراه lock انجام بشه جلوی آنومالی write skew گرفته میشه.
اما اون ۴ تا مثال بعدی یکم متفاوت هستن. چون اونها در مرحله چک کردن بررسی میکنند که رکوردی وجود نداشته باشه. در صورت نبودش میرن سراغ عمل اصلی. وقتی رکوردی وجود نداره دقیقا روی چی lock انجام بشه؟!

این پدیده که درج رکورد در دیتابیس باعث بشه در تراکنش دیگری یه شرطی برقرار بشه بهش میگن phantom. 

## Materializing conflicts
اگر مساله اصلی در پدیده phantom اینه که ما رکوردی نداریم که روی آن لاک کنیم، شاید بشه روی دیتابیس یه ابجکت ساختگی به عنوان لاک داشته باشیم؟!

مثلا در مثال زمان بندی اتاق جلسه میشه بابت هر اتاق و هر ۱۵ دقیقه یه رکورد روی دیتابیس بزنیم، مثلا برای ۶ ماه آینده. اینجوری بابت هر اتاق در هر زمان از روز آبجکتی برای لاک کردن داریم.
به این روش میگن materializing conflicts.

## Serializability

هنوز برخی آنومالی ها وجود دارند که با read committed و snapshot isolation حل نشدند.
در قسمت write skew and phantom به تعدادی از اونها اشاره کردیم.

برخی سناریوها هستن که که باهاشون خوشحال نیستم:
- درک و فهمیدن Isolation level ها سخته و به خصوص وقتی در دیتابیس ها مختلف به روش های مختلفی پیاده سازی میشن
- وقتی شما کد اپلیکیشن رو نگاه میکنید خیلی سخته که بتونید تشخیص بدید دقیقا کدام Isolation level اپلیکیشن رو safe میکنه
- ابزارهای خوبی هم وجود ندارن که بتونن race condition ها رو تشخیص بدن. تست کردن ایشوهای concurrency کار سختی هست.
Serializable isolation
به عنوان قوی ترین isolation level در نظر گرفته میشه. این روش حتی گارانتی میکنه تمام تراکنش ها طوری موازی اجرا بشن که نتیجه دقیقا همان باشد که انگار کاملا دارن متوالی اجرا میشن. 

حالا ببینیم serializable isolation چطور پیاده سازی میشه. بسیاری از دیتابیس ها از این سه تا تکنیک استفاده میکنن برای پیاده سازی این روش. (تو متن هایلایت شدن)

• Literally executing transactions in a serial order (see “Actual Serial Execution” on
page 252)
• Two-phase locking (see “Two-Phase Locking (2PL)” on page 257), which for sev‐
eral decades was the only viable option
• Optimistic concurrency control techniques such as serializable snapshot isolation
(see “Serializable Snapshot Isolation (SSI)” on page 261)


## Actual Serial Execution

ساده ترین پیاده سازی serializable isolation اینه که کلا concurrency در سطح دیتابیس حذف بشه. هر لحظه فقط و فقط یه تراکنش اجرا کنیم. با این کار ما کلا صورت مساله تشخیص و جلوگیری از conflict بین تراکنش ها رو پاک کردیم. 

برای بدست آوردن پرفورمنس خوب مولتی تردینگ خیلی در ۳۰ سال گذشته مطرح بوده، حالا چی شده که داریم به  single-threaded execution فکر میکنیم؟
- حافظه های RAM انقدر ارزان شدن که میشه تمام داده را به صورت in memory نگه داشت. اینجوری خیلی وابسته به سرعت اجرای کوئری ها روی دیتابیس نیستیم.
- دیزاینرهای دیتابیس متوجه شدن تراکنش های OLTP معمولا خیلی تعداد کمی از تراکنش های یک اپلیکیشن رو تشکیل میدن. بیشتر کوئری های آنالیتیک از دسته خوندنی هستن و میتونن روی consistent snapshot اجرا بشن.


پیاده سازی تراکنش ها به صورت سریالی در دیتابیس های VoltDB/H-Store و Redis و Datomic پیاده سازی شده . گاها پرفورمنس بهتری هم داشته چون سربار مدیریت lock رو نداشتیم.

### Encapsulating transactions in stored procedures

اوایل حیات دیتابیس ها هدف این بود که هر فعالیت کاربر به طور کاملا در قالب یک تراکنش اجرا شود. مثلا بوک کردن بلیط هواپیما که یه فعالیت milti-stage هست (ایتیج هاش تو متن هایلایت شده)‌همه شون در قالب یه تراکنش اجرا بشن. 
اما چون این پروسه توسط کاربر انجام میشه معمولا خیلی طول میکشه تا کاربر تصمیم گیری بکنه و مثلا بلیط خودشو انتخاب کننه و خرید انجام بده. اینجوری یک عالمه تراکنش باید منتظر بمونن. در نتیجه سعی میشه تراکنش های OLTP خیلی کوتاه انتخاب بشن. هر تراکنش درواقع با یک ریکوئست ttp آغاز بشه و تموم بشه.


یه اپلیکیشن میخواد کوئری بزنه، دیتا رو میخونه، ممکنه حتی بر اساس کوئری اول بیهد یه کوئری دیگه بزنه و چندین مرتبه دیتا بین دیتابیس و اپلیکیشن رفت و آمد بکنه.

درنتیجه دیتابیس هایی که تراکنش ها را کاملا متوالی اجرا میکنن اجازه نمیدن تراکنش ها به شکلی که گفته شد تعاملی و multi-stage تعریف بشه. در نتیجه اپلیکیشن باید بیاد کل کد مربوط به تراکنش را در قالب store-procedure بفرسته به دیتابیس تا کد روی دیتابیس روی دیتا اجرا بشه. store-procedure روی دیتابیس هم سریع تر اجرا میشن هم اینکه تاخیر نتوورک و IO هم ازش حذف میشه.
شکل ۷-۹ دقیقا داره همینارو نشون میده.


![[Pasted image 20250203145145.png]]


### Pros and cons of stored procedures
مزایا و معایب stored procedure ها:
Stored procedure 
ها از مدت ها قبل در دیتابیس های رابطه ای وجود داشتن و از سال ۱۹۹۹ بخشی از استاندارد sql شدند. اما به دلایل زیر از محبوبیت شون کاسته شده:
- هر دیتابیسی زبان خودش رو برای Stored procedure اراپه داد. این زبان ها پا به پای زبان های برنامه نویسی general-purpose توسعه نیافتن. در نتیجه از نظر استانداردهای امروزی بسیار زشت و قدیمی به نظر می رسند و خیلی از لایبرری ها رو ندارن.
- کدی که بخواد روی دیتابیس اجرا بشه رو سخت میشه مدیریت کرد. سخت تر میشه دیباگش کرد. سخت تر میشه در گیت کنترلش کرد. سخت تر میشه تست اش کرد. سخت تر میشه در سیستم مانیتورینگ متریک هاشو جمع کرد.
- دیتابیس چون بین چندین اپلیکیشن به صورت مشترک استفاده میشه خیلی ممکنه buttle-neck بشه. اگر stored procedure بد نوشته بشه خیلی ممکنه مشکل ایجاد کنه.

پیاده سازی های مدرن stored procedure اومدن به جای زبان PL/SQL از زبان های برنامه نویسی عام منظوره استفاده کردند. مثل مواردی که در متن هایلایت شده

دیتابیس VoltDB همچنین از stored procedures برای رپلیکیشن استفاده میکنه. به جای اینکه دیتاهای تازه نوشته شده رو از نود مستر به بقیه کپی بکنه میاد هر stored procedures رو روی تمام نودهای رپلیکیشن اجرا میکنه. به این منظور لازمه stored procedure ها deterministic باشن. طوری که روی هر نودی اجرا میشه دقیقا نتیجه مشخصی حاصل بشه. مثلا از متد رندوم نیاد استفاده کنه.

### Partitioning
گفتیم اجرای تراکنش های به صورت متوالی باعث میشه دیتابیس به bottleneck تبدیل بشه. 
در این شرایط برای اینکه بشه سیستم رو scale کرد میتونیم دیتابیس رو پارتیشن بندی کنیم که VoltDB همینکار رو انجام میده. در نتیجه میشه به تعداد پارتیشن های موجود تراکنش های موازی داشته باشیم.


گر یه تراکنش نیاز به دسترسی همزمان روی چندین پارتیشن رو داشته باشه، لازمه stored procedure به واسطه lock  بین تمام پارتیشن ها اجرا بشه.

تراکنش هایی که لازم دارن روی کلیه پارتیشن ها اجرا بشن سربار اضافه دارن و کندتر هستن. 

اکنش هایی که فقط وابسته به یک پارتیشن هستن خیلی ساختار دیتا مهم هست که این تراکنش ها پرفورمنس خوبی داشته باشن. مثلا یه دیتا مدل key-value خیلی ارحت تر پارتیشن بندی میشه. ولی وقتی روی دیتامون ایندکس های ثانویه داریم خیلی کار ساده نیست.

## Two-Phase Locking (2PL)

ما قبلا دیدیم که برای جلوگیری از dirty writes میشه از مکانیزم locking استفاده کرد.


مکانیرم  Two-phase locking به این صورته که وقتی داده ای برای نوشتن لاک میشه هیچ تراکنش دیگه ای حتی نمیتونه اونو بخونه. دسترسی به دیتا کاملا انحصاری هست.

تراکشن های خوندنی، نوشتنی ها رو بلاک میکنند و تراکنش های نوشتنی، خوندنی ها رو بلاک میکنند.

Snapshot isolation
مکانیزمش این بود :
readers never block writers
writers never block readers. 
دقیقا برعکس مکانیزم 2PL.


### Implementation of two-phase locking

دیتابیس MySQL (InnoDB) و SQL Server از 2PL به عنوان serializable isolation استفاده میکنه. DB2 ازین روش برای پیاده سازی repeatable read isolation level استفاده میکنه


بلاک کردن ریدر ها و رایترها با گذاشتن لاک روی هر آبجکت انجام میشه. اون لاک میتونه از نوع shared باشه یا از نوع exclusive.
- اگر یه تراکنش روی یه آبجکتی یه لاک از نوع shared بذاره تراکشن های دیگه هم میتونن روش آن آبجکت لاک همزمان بذارن ولی اگر قبلا یکی لاک exclusive روی یه آبجکت گذاشته باشه دیگه هیچ تراکنش دیگه اجازه نداره روش لاگ بذاره.
- وقتی تراکنش میخاد یه دیتایی رو بنویسه قبلش باید روش لاک از نوع exclusive بذاره. اگر از قبل دیتا لاگ بود باید منتظر بمونه.
- وقتی یه تراکنش اول دیتا رو میخونه. بعد میخواد بنویسه. میتونه اول لاک از نوع shared بذاره بعدش نوع لاک رو به exclusive ارتقا بده.
- وقتی یه تراکنش روی یه آبجکتی لاک گذاشت. بعدش باید لاک رو حتما آزاد کنه. یا وقتی که میخواد کامیت کند یا زمانی که میخواهد abort کند. برای همین بهش میگن دوفازی. فاز اول گذاشتن لاک و فاز دوم آزاد کردن لاک. 


این همه لاک گذاشتن ممکنه باعث ایجاد شرایط deadlock بشه. دیتابیس ها معمولا شرایط deadlock رو تشخیص میدن و اتوماتیک میان یکی از تراکنش های درگیر در deadlock رو abort میکنن. اون تراکنش abort شده باید توسط اپلیکیشن تکرار بشه. 

### Performance of two-phase locking




پرفورمنس روش two-phase locking:
مشکل اصلی این روش که باعث شده خیلی ازش استفاده نشه مساله پرفورمنس اش هست.
یه بخشیش به خاطر سربار گرفتن و آزاد کردن لاک هست. اما علت اصلیش کاهش همروندی بین تراکنش هاست. 
دیتابیس هایی که ازین روش استفاده میکنند تاخیر های ناپایداری دارن.

### Predicate locks

در همین فصل راجع به Phantoms causing write skew صحبت کردیم. اینکه دوتا تراکنش همزمان میخواستن یه اتاق جلسه رو برای یه بازه زمانی مشخص رزرو کنند. در این سناریو ما به predicate lock نیاز داریم. این مدل لاک شبیه shared/exclusive lock هستش. فقط با این تفاوت که shared/exclusive lock روی یک آبجکت ب خصوص گذاشته میشه ولی Predicate lock روی یه تعدادی از آبجکت ها که با یک شرط مچ میشن گذاشته میشه


اگر یه تراکنشی از قبل روی یک آبجکتی exclusive گذاشته که اون آبجکت با condition مربوط به Predicate lock مچ میشه، دیگه تراکنشی دیگه ای نمیتونه Predicate lock ست کنه.

اگر یه تراکنشی از قبل Predicate lock ست کرده باشه، یه تراکنش جدید نمیتونه بیاد دیتایی درج بکنه یا آپدیت بزنه که با condition مربوط به Predicate lock مچ میشه. چه قبل از آپدیت مچ بشه. چه بعد از آپدیت مچ بشه. همچین تراکنشی باید منتظر بمونه لا لاک آزاد بشه.


نکته کلیدی Predicate lock اینه که حتی میتونه روی آبجکتی اپلای بشه که هنوز در دیتابیس نیستش ولی ممکنه درج بشه بعدا یعنی phantoms هست.
با کمک Predicate lock مشکل آنومالی write skew حل میشه.


### Index-range locks

لاک predicate مشکل پرفورمنسی داره چون وقتی روی دیتابیس لاک های فراوون داریم برای ست کردن یه لاک از نوع predicate باید بیاییم تک تک لاک های موجود رو چک کنیم با condition مون تا ببینیم مجاز هستیم لاک predicate رو ست کنیم یا نه.

برای همین یه لاک دیگه وجود داره جایگزین این روش به نام index-range locking  که بهش next-key locking هم میگن.



ایده اش اینه که مثلا به جای اینکه روی زمان های خالی اتاق جلسه ۱۲۳ و تایم ۱۲ تا ۱۳ لاک بذاریم بیاییم روی آبجکت های بیشتری لاک بذاریم. یعنی روی کلیه زمان های خالی اتاق جلسه ۱۲۳. یا روی کلیه اتاق های جلسه در بازه زمانی ۱۲ تا ۱۳.

در دیتابیس زمان بندی اتاق جلسه احتمالا روی ستون room_id ایندکس داشته باشیم. یا اینکه روی دوتا ستون start_time و end_time ایندکس میذاریم.
در حالت اول که روی room_id ایندکس داریم میشه روی همین ایندکس لاک از نوع shared گذاشت تا کسی نتونه روی اتاق ۱۲۳ بوک کنه
در حالت دوم روی ساعت ۱۲ تا ۱۳ لاک میکنیم که کسی نتونه برای این بازه زمانی اتاقی بوک بکنه

در هر دو حالت یه condition به یه ایندکسی اتچ میشه. تا وقتی این لاک وجود داره هیچ تراکنش دیگری نمیتونه دیتایی درج بکنه که روی اون ایندک با اون شرط هم پوشانی داشته باشه.

اگر ایندکس مناسبی پیدا نشه که دیتابیس یتونه روش لاک از نوع Index-range lock ست کنه اون لاک رو روی کل تیبل میذاره.

## Serializable Snapshot Isolation (SSI)

تا اینجا ما یا یع سری weak isolation آشنا شدیم که خیلی قابل اعتماد نبودن و همچنین آیزولیشن serializable که خیلی هزینه پرفورمنسی داشت.
اینجا یه روش دیگه ای تحت عنوان serializable snapshot isolation (SSI) معرفی میشه که امیدوارکننده تر هست. که کاملا serializability داره ولی هزینه پرفورمنس کمتری داره. این روش در سال ۲۰۰۸ معرفی شده.
SSI 
یه ورژنی از Snapshot Isolation هست که serializablility  رو هم تضمین میکنه.
نه تنها اسنپ شات میگیره از دیتابیس بلکه مکانیزم هایی هم داره که کانفلیکت ها رو تشخیص میده و مانع از کامیت شدن شون میشه.


متد SSI هم در دیتابیس های سینگل نود و هم در مولتی نود استفاده میشه.

### Pessimistic versus optimistic concurrency control
لاک 2PL یه مکانیزم بدبینانه به حساب میاد.

اجرای Serial تراکنش ها شدیدا بدبینانه هست. به این معنی هست که هر تراکنش یه لاک exclusive روی کل دیتابیس گذاشته باشه.


